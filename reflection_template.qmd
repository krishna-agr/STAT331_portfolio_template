---
title: "STAT 331 Portfolio"
author: "Krishna Agrawal"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A-.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r wd-1-csv} Lab 5 Q1}
surveys <- read_csv(here("Week#2", "Lab_Week_2", "surveys.csv"))
```

-   `xlsx`

```{r wd-1-xlsx} Practice Activity 4}
library(readxl) 
library(tidyverse)

military <- read_xlsx(here::here("data",
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending", 
                      skip = 7, 
                      n_max = 191)
```

-   `txt`

```{r wd-1-txt} Practice Activity 5.1}
message <- read_csv(here::here("data", "scrambled_message.txt")
                      )
```

**WD-2: I can select necessary columns from a dataset.**

```{r wd-2} Lab 4 Q6}
# Create a new data set that only contains information on the 4 cities within CA
# Data set will be used in visualization
california_avocados <- city_avocados |>
  inner_join(cali_avocados,
             by = c('region' = 'cali_region')
             ) |>
  mutate(region =  as.factor(region)) |>
  # Select relavent variables
  select(AveragePrice,
         type,
         region) |>
  group_by(region, type) |>
  # Calculate the mean price for every region and type of avocado combination
  summarise(mean_price = mean(AveragePrice))
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-3-numeric} Lab 3 Q 13}
thirty_men <- hiphop_clean |>
  filter(simplify_ethnic == "white" & sex == "Male" & age > 30) |>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_fam = mean(familiarity)) 
```

-   character -- specifically a string

```{r wd-3-string} Practice Activity 5.1 Q4}
z_words <- message |>
  filter(str_detect(Word, pattern = "z$"))
print(z_words)
  
```

-   factor

```{r wd-3-factor} Lab 3, Q13}
thirty_men <- hiphop_clean |>
  filter(simplify_ethnic == "white" & sex == "Male" & age > 30) |>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_fam = mean(familiarity)) 

thirty_men |>
  slice_max(mean_fam)

thirty_men |>
  slice_min(mean_fam)
  
```

-   date

```{r wd-3-date}
# Practice Activity #5
suspects <- read_csv(here::here("data",
                                "suspect_times.csv")
                     )

suspects <- suspects |>
  mutate(Time.Spotted = ymd_hms(Time.Spotted),
         Time.Spotted = force_tz(Time.Spotted, 
                                 tzone = "America/Los_Angeles"))

suspects <- suspects |>
  filter(pm(Time.Spotted) == TRUE,
         wday(Time.Spotted) != c(3,5))

```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric
    -   REVISION - Changed inner_join to semi_join

```{r wd-4-numeric} Lab 4 Q7}
q7_california_avocados <- city_avocados |>
  # Only select data for 4 regions in CA
  semi_join(cali_avocados,
             by = c('region' = 'cali_region')) |>
  mutate( region =  as.factor(region)) |>
  # Select the relevant variables
  select(SmallAvocados, 
         LargeAvocados, 
         XLargeAvocados, 
         type, 
         region) |>
  group_by(region, type) |>
  # Calculate the total number sold of each type of avocado sold for each region
  summarise(small_avocados = mean(SmallAvocados),
            large_avocados = mean(LargeAvocados),
            xlarge_avocados = mean(XLargeAvocados)) |>
  pivot_longer(cols = c('small_avocados',
                        'large_avocados',
                        'xlarge_avocados'),
               names_to = "Avocado_Size",
               values_to = "quantity_sold") |>
  # Create a new column that contains the percentage of each type of avocado sold for each region
  mutate(percent_sold = quantity_sold / sum(quantity_sold) *100,
  # This line is set levels to the factors and specify the order in the visualization
        (Avocado_Size = factor(Avocado_Size, 
                               levels = c("small_avocados", 
                                          "large_avocados", 
                                          "xlarge_avocados"))))
```

-   character -- specifically a string

```{r wd-4-string} Practice Activity 5}
punct_symbols <- message |>
  mutate(punct = str_extract_all(Word, pattern = "[[:punct:]]")) |>
  unnest(punct) |>
  filter(nchar(punct) > 0)
print(punct_symbols)
```

-   factor

```{r wd-4-factor}
# Lab #5
hiphop_clean <- hiphop |>
  mutate(across(c(word,
                  sex,
                  ethnic,
                  familiarity),
                  as.factor
                )) 
```

-   date

```{r wd-4-date} Practice Activity #5.1}
suspects <- read_csv(here::here("data",
                                "suspect_times.csv")
                     )

suspects <- suspects |>
  mutate(Time.Spotted = ymd_hms(Time.Spotted),
         Time.Spotted = force_tz(Time.Spotted, tzone = "America/Los_Angeles"))

suspects <- suspects |>
  filter(pm(Time.Spotted) == TRUE,
         wday(Time.Spotted) != c(3,5))

Thanksgiving <- ymd(20181122, tz = "America/Los_Angeles")

timeframe <- (Thanksgiving - days(35)) %--% (Thanksgiving + days(35))

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r wd-5-left} Challenge 4}

california_avocados <- california_avocados |>
  left_join(y = med_housing_price, by = c('region' = 'city', 'year' = "Year")) |>
  mutate(year = as.character(year),
         year = as.factor(year))

```

-   `right_join()`

```{r wd-5-right}

```

-   `inner_join()`

```{r wd-5-inner}
```

-   `full_join()`

```{r wd-5-full}

```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`
-   REVISION - Changed inner_join() to semi_join()

```{r wd-6-semi} Lab 4 Q2}
# Create a new data set that contains information for only the metro regions
city_avocados <- avocados |>
  # Filtered out all information on the major regions
  anti_join(y = major_region_df,
            by = c('region' = 'major_region')) |>
  # Filtered out all information on states
  anti_join(y = state_df,
            by = c('region' = 'state')) |>
  # Filtered out all information for the "TotalUS" region.
  filter(region != "TotalUS")

# Created a new data set that contains information for only the major regions
region_avocado <- avocados |>
  semi_join(major_region_df,
            by = c('region' = 'major_region'))

```

-   `anti_join()`

```{r wd-6-anti} Lab 4 Q2}
# Create a new data set that contains information for only the metro regions
city_avocados <- avocados |>
  # Filtered out all information on the major regions
  anti_join(y = major_region_df,
            by = c('region' = 'major_region')) |>
  # Filtered out all information on states
  anti_join(y = state_df,
            by = c('region' = 'state')) |>
  # Filtered out all information for the "TotalUS" region.
  filter(region != "TotalUS")

# Created a new data set that contains information for only the major regions
region_avocado <- avocados |>
  semir_join(major_region_df,
             by = c('region' = 'major_region'))
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`
-   REVISION - Changed inner_join() to semi_join()

```{r wd-7-long} Lab4 Q7}
#| message: false
# Create a new data set for Q7
q7_california_avocados <- city_avocados |>
  # Only select data for 4 regions in CA
  semi_join(cali_avocados,
             by = c('region' = 'cali_region')) |>
  mutate( region =  as.factor(region)) |>
  # Select the relevant variables
  select(SmallAvocados, 
         LargeAvocados, 
         XLargeAvocados, 
         type, 
         region) |>
  group_by(region, type) |>
  # Calculate the total number sold of each type of avocado sold for each region
  summarise(small_avocados = mean(SmallAvocados),
            large_avocados = mean(LargeAvocados),
            xlarge_avocados = mean(XLargeAvocados)) |>
  pivot_longer(cols = c('small_avocados',
                        'large_avocados',
                        'xlarge_avocados'),
               names_to = "Avocado_Size",
               values_to = "quantity_sold") |>
  # Create a new column that contains the percentage of each type of avocado sold for each region
  mutate(percent_sold = quantity_sold / sum(quantity_sold) *100,
  # This line is set levels to the factors and specify the order in the visualization
        (Avocado_Size = factor(Avocado_Size, 
                               levels = c("small_avocados", 
                                          "large_avocados", 
                                          "xlarge_avocados"))))
```

-   `pivot_wider()`
-   REVISION - Changed inner_join() to semi_join()

```{r wd-7-wide} Lab 4 Q6}
#| message: false
#Created a dataframe to contain the names of the 4 regions in CA
cali_avocados <- data.frame(cali_region = c('LosAngeles', 
                                            'SanDiego', 
                                            'Sacramento', 
                                            'SanFrancisco'))

# Create a new data set that only contains information on the 4 cities within CA
# Data set will be used in visualization
california_avocados <- city_avocados |>
  semi_join(cali_avocados,
             by = c('region' = 'cali_region')) |>
  mutate( region =  as.factor(region)) |>
  # Select relavent variables
  select(AveragePrice,
         type,
         region) |>
  group_by(region, type) |>
  # Calculate the mean price for every region and type of avocado combination
  summarise(mean_price = mean(AveragePrice))
   
# Created a new dataframe to hold only the price differences between types of avocado
# data set will be used in visualization
mean_difference <- california_avocados |>
  pivot_wider(names_from = type,
              values_from = mean_price) |>
  mutate(difference = abs(conventional - organic))
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

Lab 4 - Writing code with documentation for each code chunk.

In all of my assignments, I have used the "here" package and have used Quarto documents

**R-2: I can write well documented and tidy code.**

-   Example 1

```{r r-2-1} Lab 4 Q7}
# Create a new data set for Q7
q7_california_avocados <- city_avocados |>
  # Only select data for 4 regions in CA
  semi_join(cali_avocados,
             by = c('region' = 'cali_region')) |>
  mutate( region =  as.factor(region)) |>
  # Select the relevant variables
  select(SmallAvocados, 
         LargeAvocados, 
         XLargeAvocados, 
         type, 
         region) |>
  group_by(region, type) |>
  # Calculate the total number sold of each type of avocado sold for each region
  summarise(small_avocados = mean(SmallAvocados),
            large_avocados = mean(LargeAvocados),
            xlarge_avocados = mean(XLargeAvocados)) |>
  pivot_longer(cols = c('small_avocados',
                        'large_avocados',
                        'xlarge_avocados'),
               names_to = "Avocado_Size",
               values_to = "quantity_sold") |>
  # Create a new column that contains the percentage of each type of avocado sold for each region
  mutate(percent_sold = quantity_sold / sum(quantity_sold) *100,
  # This line is set levels to the factors and specify the order in the visualization
        (Avocado_Size = factor(Avocado_Size, 
                               levels = c("small_avocados", 
                                          "large_avocados", 
                                          "xlarge_avocados"))))

# Create a column chart
ggplot(data = q7_california_avocados, 
       mapping = aes(x = region, 
                     y = percent_sold, 
                     fill = Avocado_Size))+
  geom_col(position = "fill") +
  facet_wrap(~type) +
  # Use dodge function to offset the x axis labels
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  # Specify the legend title and labels and change the colors of the graph 
  scale_fill_manual(values = c("#A6CEE3", 
                               "#1F78B4", 
                               "#B2DF8A"),
                    name = "Avocado Size",
                    labels = c("Small", 
                               "Large", 
                               "Extra-Large")) +
  # Specify the Axis Labels
  labs(x = 'Region of CA',
       y = "Proporation of Mean Avocados Sold")
```

-   Example 2

```{r r-2-2} Challenge 4}
# We have years from 2015 to 2018 and need median housing pricing from 2015 to 2018
"
LA 
  2015 - 502750	
  2016 - 522520
  2017 - 577690
  2018 - 588140
  
San Diego
  2015 - 530000
  2016 - 568000
  2017 - 605000
  2018 - 618500

"
#https://www.laalmanac.com/economy/ec37.php
  
"
San Fransisco 
  2015 - 729690
  2016 - 775820
  2017 - 882000
  2018 - 905000
"
#https://www.car.org/marketdata/data/housingdata
"
Sacramento 
  2015 -247575
  2016 - 286167
  2017 - 314776
  2018 - 332451
"
#https://www.zillow.com/home-values/20288/sacramento-ca/

# Create vectors with median housing pricing

la_data <- c(502750, 522520, 577690, 588140)
sd_data <- c(530000, 568000, 605000, 618500)
sf_data <- c(729690, 775820, 882000, 905000)
sac_data <- c(247575, 286167, 314776, 332451)
year <- c(2015, 2016, 2017, 2018)

# Create data set with median housing prices
med_housing_price <- data.frame(Year = year,
                                LosAngeles = la_data,
                                SanDiego = sd_data,
                                SanFrancisco = sf_data,
                                Sacramento = sac_data)

med_housing_price <- med_housing_price |>
  pivot_longer(cols = c('LosAngeles',"SanDiego", "SanFrancisco", "Sacramento"),
              names_to = "city",
              values_to = 'price')

# Joining the two datasets by year and region

california_avocados <- california_avocados |>
  left_join(y = med_housing_price, by = c('region' = 'city', 'year' = "Year")) |>
  mutate(year = as.character(year),
         year = as.factor(year))

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1

```{r r-3-1} Lab 3 Q11}
#| output: false
twenty_younger <- hiphop_clean |>
  filter(age < 20) |>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_fam = mean(familiarity))
  
twenty_younger |>
  slice_max(mean_fam)

twenty_younger |>
  slice_min(mean_fam)
```

-   Example 2

```{r r-3-2} Lab 8 Step 1}
# Function that takes a noun and makes it plural
# Arguments -- gift -- A string or vector of strings
# Return -- A string or vector of strings with the pluralized words

pluralize_gift <- function(gift){

  stopifnot(is.vector(gift) || is.character(gift)
            )
  
  
  gift <- 
    case_when(
      str_detect(string = gift, 
                 pattern = 'oo') ~ str_replace(string = gift,
                                               pattern = 'oo',
                                               replacement = 'ee'),
      str_detect(string = gift, 
                 pattern = 'y$') ~ str_replace(string = gift,
                                               pattern = 'y$', 
                                               replacement = 'ies'),
      TRUE ~ str_c(string = gift, 's', sep = '')
  )

return(gift)

}
  
```

## Data Visualization & Summarization

**\*\*DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables

```{r dvs-1-num} Lab 2 Q6}
ggplot(data = surveys, mapping = aes(x = weight, y = hindfoot_length)) +  
   geom_jitter(alpha=.3)
```

-   numeric variables and categorical variables

```{r dvs-2-num-cat} Lab 5 Q1.2}
ggplot(data = surveys, 
       mapping = aes(y = fct_reorder(species,weight), 
                     x = weight)) +
   geom_jitter(color = "darkseagreen",
               alpha = .1) +
   geom_boxplot(outlier.shape = NA) +
   labs(y = '',
        x = "Weight (grams)", 
        title = "Species of Animal vs Weight in grams") +
   theme(plot.title.position = 'plot')
```

-   categorical variables

```{r dvs-2-cat} Lab 5, Q3}
ggplot(data = count_survey,
       mapping = aes(y = day_week,
                     x = n,
                     fill = day_week)) +
  geom_bar(stat = "identity",
           show.legend = FALSE) +
  labs(y = '',
       x = "", 
       title = "Number of Rodents Captured by the Day of the Week") +
  theme(plot.title.position = 'plot') 
  
```

-   dates

```{r dvs-2-date} Lab 5 Q4}
ggplot(data = mean_weight_survey, 
       mapping = aes(y = mean_weight, 
                     x = year,
                     color = fct_reorder2(.f = genus,
                                          .y = mean_weight,
                                          .x = year))) +
  geom_line() +
  labs(y = '',
       x = "Time", 
       title = "Mean Weight (grams) by Genus Over Time") +
  guides(color = guide_legend(title = "Genus")) +
  theme(plot.title.position = 'plot') 
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1

```{r dvs-2-1} Lab 5 Q4}
ggplot(data = mean_weight_survey, 
       mapping = aes(y = mean_weight, 
                     x = year,
                     color = fct_reorder2(.f = genus,
                                          .y = mean_weight,
                                          .x = year))) +
  geom_line() +
  labs(y = '',
       x = "Time", 
       title = "Mean Weight (grams) by Genus Over Time") +
  guides(color = guide_legend(title = "Genus")) +
  theme(plot.title.position = 'plot') 
```

-   Example 2

```{r dvs-2-2} Lab 4 Q7}
# Create a column chart
ggplot(data = q7_california_avocados, 
       mapping = aes(x = region, 
                     y = percent_sold, 
                     fill = Avocado_Size))+
  geom_col(position = "fill") +
  facet_wrap(~type) +
  # Use dodge function to offset the x axis labels
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  # Specify the legend title and labels and change the colors of the graph 
  scale_fill_manual(values = c("#A6CEE3", 
                               "#1F78B4", 
                               "#B2DF8A"),
                    name = "Avocado Size",
                    labels = c("Small", 
                               "Large", 
                               "Extra-Large")) +
  # Specify the Axis Labels
  labs(x = 'Region of CA',
       y = "Proporation of Mean Avocados Sold")
```

**DVS-3: I show creativity in my visualizations**

-   Example 1

```{r dvs-3-1} Lab 7 Q2.2}
ggplot(data = blackfoot_fish_na,
       mapping = aes(x = year, 
                     y = weight,
                     fill = trip)) +
  geom_col(show.legend = FALSE) +
  facet_grid(trip ~ section) +
  labs(y = '',
       x = "Year", 
       title = "Number of Missing Fish Weight Values",
       subtitle = "Based on Blackfoot River Section and Trip Number") +
  theme(plot.title.position = 'plot') +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  scale_fill_brewer(palette = 'Set1') 
```

-   Example 2

```{r dvs-3-2} Lab 5 Q3-4}
ggplot(data = mean_weight_survey, 
       mapping = aes(y = mean_weight, 
                     x = year,
                     color = fct_reorder2(.f = genus,
                                          .y = mean_weight,
                                          .x = year))) +
  geom_line() +
  labs(y = '',
       x = "Time", 
       title = "Mean Weight (grams) by Genus Over Time") +
  guides(color = guide_legend(title = "Genus")) +
  theme(plot.title.position = 'plot') 
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1

```{r dvs-4-1} Lab 3 Q11}
#| output: false
twenty_younger <- hiphop_clean |>
  filter(age < 20) |>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_fam = mean(familiarity))
  
twenty_younger |>
  slice_max(mean_fam)

twenty_younger |>
  slice_min(mean_fam)
```

-   Example 2

```{r dvs-4-2} Lab 4 Q7}
q7_california_avocados <- city_avocados |>
  # Only select data for 4 regions in CA
  semi_join(cali_avocados,
             by = c('region' = 'cali_region')) |>
  mutate( region =  as.factor(region)) |>
  # Select the relevant variables
  select(SmallAvocados, 
         LargeAvocados, 
         XLargeAvocados, 
         type, 
         region) |>
  group_by(region, type) |>
  # Calculate the total number sold of each type of avocado sold for each region
  summarise(small_avocados = mean(SmallAvocados),
            large_avocados = mean(LargeAvocados),
            xlarge_avocados = mean(XLargeAvocados)) |>
  pivot_longer(cols = c('small_avocados',
                        'large_avocados',
                        'xlarge_avocados'),
               names_to = "Avocado_Size",
               values_to = "quantity_sold") |>
  # Create a new column that contains the percentage of each type of avocado sold for each region
  mutate(percent_sold = quantity_sold / sum(quantity_sold) *100,
  # This line is set levels to the factors and specify the order in the visualization
        (Avocado_Size = factor(Avocado_Size, 
                               levels = c("small_avocados", 
                                          "large_avocados", 
                                          "xlarge_avocados"))))
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r dvs-5-1} Lab 4 Q6}
california_avocados <- city_avocados |>
  semi_join(cali_avocados,
             by = c('region' = 'cali_region')) |>
  mutate( region =  as.factor(region)) |>
  # Select relavent variables
  select(AveragePrice,
         type,
         region) |>
  group_by(region, type) |>
  # Calculate the mean price for every region and type of avocado combination
  summarise(mean_price = mean(AveragePrice))
```

-   Example 2

```{r dvs-5-2} Lab 4 Q7}
q7_california_avocados <- city_avocados |>
  # Only select data for 4 regions in CA
  semi_join(cali_avocados,
             by = c('region' = 'cali_region')) |>
  mutate(region =  as.factor(region)) |>
  # Select the relevant variables
  select(SmallAvocados, 
         LargeAvocados, 
         XLargeAvocados, 
         type, 
         region) |>
  group_by(region, type) |>
  # Calculate the total number sold of each type of avocado sold for each region
  summarise(small_avocados = mean(SmallAvocados),
            large_avocados = mean(LargeAvocados),
            xlarge_avocados = mean(XLargeAvocados)) |>
  pivot_longer(cols = c('small_avocados',
                        'large_avocados',
                        'xlarge_avocados'),
               names_to = "Avocado_Size",
               values_to = "quantity_sold") |>
  # Create a new column that contains the percentage of each type of avocado sold for each region
  mutate(percent_sold = quantity_sold / sum(quantity_sold) *100,
  # This line is set levels to the factors and specify the order in the visualization
        (Avocado_Size = factor(Avocado_Size, 
                               levels = c("small_avocados", 
                                          "large_avocados", 
                                          "xlarge_avocados"))))
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r dvs-6-1} Challenge 9 Q10}
state_name |> 
  filter(str_detect(string = Name, 
                    pattern = 'Al(lan|an|len)$'),
         State == 'PA' | State == 'CA',
         Year == 2000) |>
  group_by(Name, State) |>
  summarize(n = sum(Count)) |>
  group_by(State) |>
  mutate(prop = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = Name, 
              values_from = prop) |>
  knitr::kable(format = "html", 
               digits = 3, 
               col.names = 
                 c("State", 
                   "Alan", 
                   "Allan",
                   "Allen"),
               caption = "Pectentage of variations of 'Allan' by PA and CA")|>
  kable_material_dark(c("striped", "hover"))|>
  kableExtra::kable_classic(bootstrap_options = "striped", 
                            font_size = 28)
```

-   Example 2

```{r dvs-6-2} Challenge 9 Q1}
state_name <- state_name |>
  rename("Sex" = "Gender")

state_name |>
  head(200) |>
  datatable(class = 'hover',
            filter = 'top', 
            options = list(pageLength = 20))
```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r dvs-7-1} Challenge 9 Q3.1}
state_name |>
  filter(Name == "Allison") |>
  pivot_wider(names_from = Sex,
              values_from = Count,
              values_fill = 0) |>
  group_by(State) |>
  summarise(across(.cols = c('F','M'),
                   .fns = sum)) |>
  knitr::kable(format = "html", 
               digits = 3, 
               col.names = 
                 c("State", 
                   "Female", 
                   "Male"),
               caption = 'Number of Female and Male "Allison" based on State' )|>
  kable_material(c("striped", "hover"))|>
  kableExtra::kable_classic(bootstrap_options = "striped", 
                            font_size = 20)         
```

-   Example 2

```{r dvs-7-2} Challenge 9 Q10}
state_name |> 
  filter(str_detect(string = Name, 
                    pattern = 'Al(lan|an|len)$'),
         State == 'PA' | State == 'CA',
         Year == 2000) |>
  group_by(Name, State) |>
  summarize(n = sum(Count)) |>
  group_by(State) |>
  mutate(prop = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = Name, 
              values_from = prop) |>
  knitr::kable(format = "html", 
               digits = 3, 
               col.names = 
                 c("State", 
                   "Alan", 
                   "Allan",
                   "Allen"),
               caption = "Pectentage of variations of 'Allan' by PA and CA")|>
  kable_material_dark(c("striped", "hover"))|>
  kableExtra::kable_classic(bootstrap_options = "striped", 
                            font_size = 28)
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call

```{r pe-1-one-call} Lab 4 Q3}
# Use the dataset that contains the information on the major regions
region_avocado |>
  # Select observations that occur in 2017 and are organic
  filter(year == 2017 & type == "organic") |>
  # Select only the SmallAvocados and region coloumn
  select(SmallAvocados, region) |>
  group_by(region) |>
  # Calculate the sum of all small avocado sales based on each region
  summarise(totalSold = sum(SmallAvocados)) |>
  # Obtain the value with the highest number of organic small avocados sold
  slice_max(totalSold)
```

-   `across()`

```{r pe-1-across} Lab 3, Q4}
# Changing Characters to Factors
hiphop_clean <- hiphop |>
  mutate(across(c(word,
                  sex,
                  ethnic,
                  familiarity),
                  as.factor
                ))
```

-   map()

```{r pe-1-map-1} Practice Activity 9}
set.seed(1957)

music_man <- function(n_tromb, n_cor, n_reed){
  
  trombones <- rnorm(n_tromb, mean = 4.6, sd = .8)
  cornets <- runif(n_cor, min = 1.5, max = 3.5)
  reeds <- rchisq(n_reed, df = 4)
  
  return(sum(trombones, cornets, reeds))
  
}

my_weights <- map_dbl(.x = 1:1000, 
                      .f = ~ music_man(n_tromb = 76, n_cor = 110, n_reed = 1035)
) 

```

**PE-2: I can write functions to reduce repetition in my code**

-   Example 1

```{r pe2-1} Lab 8 Q1}
pluralize_gift <- function(gift){

  stopifnot(is.vector(gift) || is.character(gift)
            )
  
  
  gift <- 
    case_when(
      str_detect(string = gift, 
                 pattern = 'oo') ~ str_replace(string = gift,
                                               pattern = 'oo',
                                               replacement = 'ee'),
      str_detect(string = gift, 
                 pattern = 'y$') ~ str_replace(string = gift,
                                               pattern = 'y$', 
                                               replacement = 'ies'),
      TRUE ~ str_c(string = gift, 's', sep = '')
  )

return(gift)

}
```

-   Example 2

```{r pe2-1} Lab 7 Step 3.1}
rescale_01 <- function(x) {
  
  stopifnot(is.numeric(x), 
            length(x) > 1)
  
  min_max_val <- range(x, na.rm = TRUE)
  
  standardized <- ((x - min_max_val[1]) / (min_max_val[2] - min_max_val[1]))
  
  return(standardized)
}


```

**PE-3: I can use iteration to reduce repetition in my code**

-   across()

```{r pe-3-across} Lab 7, Q2.1}

blackfoot_fish |>
  summarise(across(.cols = everything(),
                   .fns = ~ sum(is.na(.x))))
```

-   map()

```{r pe-3-map-1} Practice Activity 9}
set.seed(1957)

music_man <- function(n_tromb, n_cor, n_reed){
  
  trombones <- rnorm(n_tromb, mean = 4.6, sd = .8)
  cornets <- runif(n_cor, min = 1.5, max = 3.5)
  reeds <- rchisq(n_reed, df = 4)
  
  return(sum(trombones, cornets, reeds))
  
}

my_weights <- map_dbl(.x = 1:1000, 
                      .f = ~ music_man(n_tromb = 76, n_cor = 110, n_reed = 1035)
) 
```

```{r pe-3-map-2} Lab 8 Step 4}

lyrics <- map_chr(1:12,
        .f = ~sing_day(dataset = xmas2, line = .x, phrase_col = Full.Phrase))

cat(lyrics, sep = '\n', fill = TRUE)

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1

```{r pe-4-1} Lab 9 Q3.3}
state_name |>
  filter(Name == "Allison") |>
  mutate(year = as.factor(Year)) |>
  group_by(year) |>
  summarise(n = sum(Count)) |>
  ggplot(mapping = aes(x = year,
                       y = n,
                       group = 1)) +
  geom_line() +
  labs(y = '',
       x = "Year", 
       title = 'Popularity of the Name "Allison" over Time') +
  theme(plot.title.position = 'plot') +
  scale_x_discrete(guide = guide_axis(n.dodge = 2))
```

-   Example 2

```{r pe-4-2}  Lab 3 Q11}
#| output: false
twenty_younger <- hiphop_clean |>
  filter(age < 20) |>
  mutate(familiarity = as.numeric(familiarity)) |>
  group_by(word) |>
  summarize(mean_fam = mean(familiarity))
  
twenty_younger |>
  slice_max(mean_fam)

twenty_younger |>
  slice_min(mean_fam)

```

## Data Simulation and Modeling

**DSM-1: I can simulate data from a *variety* of probability models**

-   Example 1

```{r dsm-1-1} Practice Activity 9 - WarmUp}

qunif(.95, min = 1.5, max = 3.5)
qnorm(.10, mean = 4.6, sd = .8)
pnorm(5, mean = 4.6, sd = 0.8, lower.tail = FALSE)


```

-   Example 2

```{r dsm-1-2} Practice Activity 9}
set.seed(1957)

music_man <- function(n_tromb, n_cor, n_reed){
  
  trombones <- rnorm(n_tromb, mean = 4.6, sd = .8)
  cornets <- runif(n_cor, min = 1.5, max = 3.5)
  reeds <- rchisq(n_reed, df = 4)
  
  return(sum(trombones, cornets, reeds))
  
}

my_weights <- map_dbl(.x = 1:1000, 
                      .f = ~ music_man(n_tromb = 76, n_cor = 110, n_reed = 1035)
) 

filter_func <- function(x) {
  x < 4532 
}

filtered_list <- keep(my_weights, filter_func)
```

**DSM-2: I can fit a linear regression and extract necessary summary measures**

-   Example 1

```{r dsm-2-1} Lab 9 Q4}
state_name |> 
  filter(Name == 'Allison')  |>
  group_by(Year) |>
  summarize(n = sum(Count)) |>
  lm(n ~ Year, data = _)
```

-   Example 2

```{r dsm-2-2} Practice Activity 9}

message_lm <- message |>
  lm(weight_after ~ weight_before, 
     data = _)

message_lm |>
  broom::augment() |> 
  ggplot(mapping = aes(y = .resid, x = .fitted)) +
  geom_point()

```

## Revising My Thinking

Throughout the course of this class, I have made it a priority to reflect on the feedback I receive and to incorporate that feedback into my future assignments. For example, I received a "G" grade for Lab 3, but I used that feedback to improve my work in subsequent assignments. I will also be submitting the Lab #3 revision alongside this reflection. I have made a conscious effort to pay attention to details such as ensuring my axes are in the correct units and making sure there are no warnings or messages when I load packages or create visualizations. Even though I have received an "S" for the majority of my assignments, I still try to improve on my understanding of R. For example, on lab 4, even though I got an "S" for specific problems, i went back and revised the assignment based on the feedback given.

## Extending My Thinking

During the initial weeks of this class, it was hard to go above and beyond, as the class only met once for the first two weeks, and it had been over a year since I last engaged in programming as part of my BUS 392 course. As a result, during the first two lab and challenge assignments, I could not devote extra time to incorporate "extras". I opted for the least "spicy" option for my challenge assignment as I did not have the bandwidth at the time to go above and beyond.

However, later on, beginning in weeks #3 and #4, I made a priority to go above in my assignments. For instance, in Lab 4, I used external resources to learn how to remove the scientific notation from my axis and how to specify the levels in my factor variable in order to correct the order in my visualizations. While using these external sources to enhance my visualizations, I made sure to include proper citation of sources. I also started to document my code by inserting comments before each line of code which provides the reader insight into my thought process.

I also used what we learned in Will Chase's Presentation in Week#5 throughout the rest of the quarter to make sure my plots were adhering to the best practices. I also read through the linked website regarding datatables in the slides for week #9 in order to create creative table outputs.

## Peer Support & Collaboration

I feel that I have definitely satisfied the requirements for this section. I have made a strong commitment to being a supportive and collaborative group member. So far, I have attended every class and have been fully engaged in the practice activities with my assigned group. I took the initiative to create a group chat and our own discord server so that we could more easily help each other by sharing screens or uploading screenshots of our code and errors. I have also consistently responded to the requests for help from my group members. However, it has been hard for me to contribute to the STAT 331 discord, but going forward I will try to make it a priority.

I take great pride in my peer-code reviews, as I believe they are an important aspect of the learning process. I make it a priority to provide comprehensive and respectful feedback, making sure to elaborate on both the strengths and areas for improvement in each person's code. I always make sure to reference the style guidelines, and in my last peer-review, I was impressed by the thorough documentation of the code I reviewed, which included comments for each section. In the future, I plan to document my own code in a similar manner to facilitate the peer-review process and to promote clear and concise communication.

![](images/image-1301924154.png){width="247"}
